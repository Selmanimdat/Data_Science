{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47a9fbef",
   "metadata": {},
   "source": [
    "# #Tek Değişkenli Outlier Baskılama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd677450",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_sinir-->22.0\n",
      "ust_sinir-->38.0\n",
      "baskılanıyor...highwaympg\n",
      "alt_sinir-->13.0\n",
      "ust_sinir-->37.0\n",
      "baskılanıyor...citympg\n",
      "alt_sinir-->4750.0\n",
      "ust_sinir-->6750.0\n",
      "baskılanıyor...peakrpm\n",
      "alt_sinir-->120.0\n",
      "ust_sinir-->200.0\n",
      "baskılanıyor...horsepower\n",
      "alt_sinir-->7.0\n",
      "ust_sinir-->11.0\n",
      "baskılanıyor...compressionratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Selman\\AppData\\Local\\Temp\\ipykernel_30668\\799582577.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta[aykiri_tf_alt] = alt_sinir\n",
      "C:\\Users\\Selman\\AppData\\Local\\Temp\\ipykernel_30668\\799582577.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_meta[aykiri_tf_ust] = ust_sinir\n"
     ]
    }
   ],
   "source": [
    "#data--> analiz edilecek data\n",
    "#columns--> analiz edilecek numerik kolonlar\n",
    "#library\n",
    "import pandas as pd\n",
    "\n",
    "#örnek girdi***********\n",
    "data = {\n",
    "    \"highwaympg\": [32, 30, 28, 35, 18],\n",
    "    \"citympg\": [28, 25, 22, 29, 15],\n",
    "    \"peakrpm\": [5500, 6000, 5800, 6200, 5400],\n",
    "    \"horsepower\": [150, 170, 140, 160, 380],\n",
    "    \"compressionratio\": [9.0, 9.5, 10.0, 8.5, 7.0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "data=df\n",
    "#*******************************\n",
    "\n",
    "\n",
    "\n",
    "def numeric_outlier_analysis(data, columns):\n",
    "    for i in columns:\n",
    "        df_meta = data[i]\n",
    "        Q1 = df_meta.quantile(0.25)\n",
    "        Q3 = df_meta.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        alt_sinir = abs(Q1 - 1.5 * IQR)\n",
    "        ust_sinir = abs(Q3 + 1.5 * IQR)\n",
    "        print(\"alt_sinir-->\" + str(alt_sinir))\n",
    "        print(\"ust_sinir-->\" + str(ust_sinir))\n",
    "        aykiri_tf_alt = (df_meta < alt_sinir)\n",
    "        aykiri_tf_ust = (ust_sinir < df_meta)\n",
    "        print(\"baskılanıyor...\" + str(i))\n",
    "        df_meta[aykiri_tf_alt] = alt_sinir\n",
    "        df_meta[aykiri_tf_ust] = ust_sinir\n",
    "        data[i]=df_meta\n",
    "        \n",
    "        \n",
    "        \n",
    "#çalıştırma bölümü \n",
    "#örnek\n",
    "col = [\"highwaympg\", \"citympg\", \"peakrpm\", \"horsepower\", \"compressionratio\"]\n",
    "        \n",
    "numeric_outlier_analysis(data, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0978022",
   "metadata": {},
   "source": [
    "## \"object\" tipini \"category\" ye çevirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "961fdc9b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object tipinde kolon yok.\n"
     ]
    }
   ],
   "source": [
    "#dönüştürelecek DataFrame adı -->data\n",
    "\n",
    "columns_l = list(data.columns)\n",
    "categorical_columns = []\n",
    "\n",
    "object_to_category = False  # Önce döngüde herhangi bir değişiklik yapılmadığını varsayalım\n",
    "\n",
    "for i in columns_l:\n",
    "    if data[i].dtype == 'object' or data[i].dtype.name == 'category':\n",
    "        categorical_columns.append(i)\n",
    "        if data[i].dtype == 'object':\n",
    "            object_to_category = True  # En az bir \"object\" tipinde sütun bulundu\n",
    "\n",
    "# \"object\" tipindeki sütunları \"category\" tipine dönüştürme ve çevrilenleri yazdırma\n",
    "for column in categorical_columns:\n",
    "    if data[column].dtype == 'object':\n",
    "        data[column] = data[column].astype('category')\n",
    "\n",
    "# Eğer dönüştürme yapıldıysa, çevrilenleri yazdırma\n",
    "if object_to_category:\n",
    "    print(\"Kategorik değişkene çevrilenler:\")\n",
    "    for column in categorical_columns:\n",
    "        if data[column].dtype == 'category':\n",
    "            print(column)\n",
    "else:\n",
    "    print(\"Object tipinde kolon yok.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82303ce1",
   "metadata": {},
   "source": [
    "## Dummy Değişken Dönüşümü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62526f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#girdi--> data\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Kategorik sütunlara dönüşüm ve (n-1) kuralı uygulama\n",
    "categorical_columns = df.select_dtypes(include=[\"category\"]).columns\n",
    "\n",
    "for column in categorical_columns:\n",
    "    dummies = pd.get_dummies(df[column], prefix=column, drop_first=True)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df.drop(column, axis=1, inplace=True)\n",
    "    \n",
    "data=df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb3cd8a",
   "metadata": {},
   "source": [
    "## oversampling under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df[df.quality==3]     # MINORITY          \n",
    "df_4 = df[df.quality==4]     # MINORITY          \n",
    "df_5 = df[df.quality==5]     # MAJORITY\n",
    "df_6 = df[df.quality==6]     # MAJORITY\n",
    "df_7 = df[df.quality==7]     # MINORITY\n",
    "df_8 = df[df.quality==8]     # MINORITY\n",
    "\n",
    "#We had already established it earlier that except quality 5 and 6, all the others are minority!\n",
    "\n",
    "\n",
    "\n",
    "# Oversample MINORITY Class to make balance data :\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_3_upsampled = resample(df_3, replace=True, n_samples=600, random_state=12) \n",
    "df_4_upsampled = resample(df_4, replace=True, n_samples=600, random_state=12) \n",
    "df_7_upsampled = resample(df_7, replace=True, n_samples=600, random_state=12) \n",
    "df_8_upsampled = resample(df_8, replace=True, n_samples=600, random_state=12) \n",
    "\n",
    "# Decreases the rows of Majority one's to make balance data :\n",
    "df_5_downsampled = df[df.quality==5].sample(n=600).reset_index(drop=True)\n",
    "df_6_downsampled = df[df.quality==6].sample(n=600).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0425ee",
   "metadata": {},
   "source": [
    "## standardizasyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d995e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Veriyi alın\n",
    "# x_train: eğitim verisi\n",
    "# x_test: test verisi\n",
    "\n",
    "# Seçilen dummy değişken sütunları\n",
    "selected_dummy_cols = [\"dummy_col_1\", \"dummy_col_2\", \"dummy_col_3\"]\n",
    "\n",
    "# Seçilen dummy değişkenleri çıkarın ve kalan sütunlar üzerinde işlem yapın\n",
    "x_train_without_dummy = x_train.drop(selected_dummy_cols, axis=1)\n",
    "x_test_without_dummy = x_test.drop(selected_dummy_cols, axis=1)\n",
    "\n",
    "# StandardScaler nesnesini oluşturun\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Eğitim verisini kullanarak ölçeklendirme işlemini öğrenin ve uygulayın\n",
    "x_train_scaled = scaler.fit_transform(x_train_without_dummy)\n",
    "\n",
    "# Test verisini eğitim verisine göre aynı şekilde ölçeklendirin\n",
    "x_test_scaled = scaler.transform(x_test_without_dummy)\n",
    "\n",
    "# Dummy değişken sütunları ile ölçeklendirilmiş verileri birleştirin\n",
    "x_train_scaled_df = pd.DataFrame(x_train_scaled, columns=x_train_without_dummy.columns, index=x_train_without_dummy.index)\n",
    "x_test_scaled_df = pd.DataFrame(x_test_scaled, columns=x_test_without_dummy.columns, index=x_test_without_dummy.index)\n",
    "\n",
    "# Dummy değişken sütunları ekleyerek ölçeklendirilmiş verileri tamamlanmış veriye dönüştürün\n",
    "x_train_final = pd.concat([x_train_scaled_df, x_train[selected_dummy_cols]], axis=1)\n",
    "x_test_final = pd.concat([x_test_scaled_df, x_test[selected_dummy_cols]], axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
